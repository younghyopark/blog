<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Multi-fingered Dexterous Manipulation from Locomotion Perspective | Younghyo's Blog</title><meta name=keywords content><meta name=description content="Motivation Although it seems like a totally different class of work in robotics, Locomotion and Dexterous Manipulation in fact has some weird similarities — both work with a similar hardware (set of multiple identical kinematic chains) and the nature of the task itself (making selective contacts with an object to achieve the goal) is also very similar.
Locmotion and Multi-fingered Dexterous Manipulation share many similarities.
Of course there are huge differences in detail, but still, it’s similar enough to make one wonder"><meta name=author content="Younghyo Park"><link rel=canonical href=https://younghyopark.me/blog/posts/locomotion-and-dexterous-manipulation/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/blog/assets/css/stylesheet.3f686b32a01896608101ddd02e74a3e844730b49647eed116121d0884272d7f2.css integrity="sha256-P2hrMqAYlmCBAd3QLnSj6ERzC0lkfu0RYSHQiEJy1/I=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://younghyopark.me/blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://younghyopark.me/blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://younghyopark.me/blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://younghyopark.me/blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://younghyopark.me/blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Multi-fingered Dexterous Manipulation from Locomotion Perspective"><meta property="og:description" content="Motivation Although it seems like a totally different class of work in robotics, Locomotion and Dexterous Manipulation in fact has some weird similarities — both work with a similar hardware (set of multiple identical kinematic chains) and the nature of the task itself (making selective contacts with an object to achieve the goal) is also very similar.
Locmotion and Multi-fingered Dexterous Manipulation share many similarities.
Of course there are huge differences in detail, but still, it’s similar enough to make one wonder"><meta property="og:type" content="article"><meta property="og:url" content="https://younghyopark.me/blog/posts/locomotion-and-dexterous-manipulation/"><meta property="og:image" content="https://younghyopark.me/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-20T14:27:59-05:00"><meta property="article:modified_time" content="2023-09-20T14:27:59-05:00"><meta property="og:site_name" content="Younghyo's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://younghyopark.me/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Multi-fingered Dexterous Manipulation from Locomotion Perspective"><meta name=twitter:description content="Motivation Although it seems like a totally different class of work in robotics, Locomotion and Dexterous Manipulation in fact has some weird similarities — both work with a similar hardware (set of multiple identical kinematic chains) and the nature of the task itself (making selective contacts with an object to achieve the goal) is also very similar.
Locmotion and Multi-fingered Dexterous Manipulation share many similarities.
Of course there are huge differences in detail, but still, it’s similar enough to make one wonder"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://younghyopark.me/blog/posts/"},{"@type":"ListItem","position":3,"name":"Multi-fingered Dexterous Manipulation from Locomotion Perspective","item":"https://younghyopark.me/blog/posts/locomotion-and-dexterous-manipulation/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Multi-fingered Dexterous Manipulation from Locomotion Perspective","name":"Multi-fingered Dexterous Manipulation from Locomotion Perspective","description":"Motivation Although it seems like a totally different class of work in robotics, Locomotion and Dexterous Manipulation in fact has some weird similarities — both work with a similar hardware (set of multiple identical kinematic chains) and the nature of the task itself (making selective contacts with an object to achieve the goal) is also very similar.\nLocmotion and Multi-fingered Dexterous Manipulation share many similarities.\nOf course there are huge differences in detail, but still, it’s similar enough to make one wonder","keywords":[],"articleBody":"Motivation Although it seems like a totally different class of work in robotics, Locomotion and Dexterous Manipulation in fact has some weird similarities — both work with a similar hardware (set of multiple identical kinematic chains) and the nature of the task itself (making selective contacts with an object to achieve the goal) is also very similar.\nLocmotion and Multi-fingered Dexterous Manipulation share many similarities.\nOf course there are huge differences in detail, but still, it’s similar enough to make one wonder\n“What kind of lessons can we take from quadruped locomotion for dexterous manipulation, or, vice-versa?”\nIn fact, I’m already seeing some papers with a similar motivation — recent paper from Malik’s group that adapts the idea of RMA (a technique mainly used for locomotion) for dexterous manipulation In-Hand Object Rotation via Rapid Motor Adaptation | pdf is definitely one of them.\nThis post aims to discuss things that one can learn and adapt from one another — techniques from locomotion domain that can be applied to dexterous manipulation, and vice-versa.\nDifferences at a glance Dexterous Manipulation Locomotion contact made with diverse (graspable) objects diverse terrains diversity of “object/terrain” handled with dataset of objects (e.g. parts of ShapeNet) procedural process of random terrain generation contact location all parts of hand — finger tips, fingers, palm usually only with their round feet gravity direction entire SO(3), especially when attached to arm generally downwards, slightly changes when climing uphill/downhill degrees of freedom 16 dof (4 x 4 for each fingers)* 12 dof (4 x 3 for each leg) typical state inputs to the policy depth + proprioceptive (visual information is crucial) proprioceptive (mostly don’t require visual information) Rewards during RL tracking explicit spatial goals (e.g. SE(3) poses) + some auxiliary rewards tracking time-derivatives (e.g. body velocity) + some auxiliary rewards Sim2Real - DR randomizes object friction, size, mass, joint control parameters, … randomizes terrain, ground friction, restitution, body mass/com .. Sim2Real - SysID e.g. robot dynamics sysID with massively parallel simulator e.g. RMA (online sysID/adaptation during test-time) RL techniques student-teacher learning student-teacher learning, curriculum learning (e.g. increasing difficulties of terrain, tracking velocity) failure recovery - often trains separate policy that can recover from fallen down states other trends tactile sensors being added to make the policy more robust better constraint handling techniques other than reward shaping https://arxiv.org/pdf/2308.12517.pdf are gaining attention these days Let’s further anaylze these differences in detail.\nTerrain Generations vs Object Datasets As far as I know, locomotion policies are trained over randomized terrains that’s generated by some heuristic algorithms (e.g. using Perlin noise two generate 2d heightmaps, diamond square algorithm for fractal terrains). Basically, they rely on “terrain generation algorithms” rather than a fixed dataset of terrains.\nsummarization about terrain generation techniques from some paper ..\nGenerating a Terrain-Robustness Benchmark for Legged Locomotion: A…\nTerrains, in the domain of terrain-aware legged locomotion, are typically represented by heightmaps, i.e., twodimensional matrices of real numbers indicating the height at different points. A traditional method for terrain generation is to use Perlin noise [19], as is adopted by existing works [3] [7]. Although policies can be trained in simulation with such terrains, verifications must be done on real robots after sim-to-real transfer, because using Perlin noise does not lead to realistic heightmaps [9].\nAlternative methods are to generate fractal terrains, e.g., to use the diamond square algorithm [20] and the fractal brownian motion algorithm [21]. However, it is difficult to regard them as realistic.\nAn emerging way to generate realistic terrains is to use GANs [22], where a discriminator tries to classify whether a sample comes from the dataset, and a generator tries to cheat the discriminator by generating samples from noises. Examples of GAN-based terrain generation are [23] and [24]. Yet, to achieve partially controllable generation and actively generate a dataset, we need interactive terrain authoring based on conditional GANs [10]. To be specific, the discriminator classifies whether the samples together with certain features are from the training dataset, and the generator generates fake samples from not only noises but also the features. Finally, the generator can generate realistic terrains from given input features, and the noises only affect smallscale details.\nThis approach relies to the hope that such synthesized terrains well reflects the diverse characteristics of real-world terrains (at least locally) so that the trained controller will well-behave in real-world. Major benefit of using terrain generation methods (with explicit parameters) is that we can control the difficulties of the task by adjusting parameter of terrain generation — which leads to the concept of curriculum learning as well.\nOn the other hand, dexterous manipulation relies on a fixed (but sufficiently large) training dataset of objects. This approach relies to the hope that the training dataset covers wide enough variety of objects so that the trained policy can be well generalized over unseen objects as well — which can sometimes be a bit unrealistic considering the vast range of objects. Also, it’s quite difficult to introduce a notion of “difficulty” in terms of object in this setting — which is also not really suited for curriculum learning setting as well.\nIt is thus natural, but still not straightforward, to think whether we can use the same approach of terrain generation in dexterous manipulation — using 3D shape generation methods during training, instead of fixed object datasets.\nTC: it’s tempting to think about applying techniques used in locomotion to manipulation. but rather than think about the techniques themselves, might be better to start with what are we trying to achieve by transferring the techniques? why?\nRewards As a great exemplary of both worlds, I took the formulations Visual Dexterity (Chen et al.) and Rapid Locomotion (Margolis et al.) to compare the rewardsterms . There were two observations:\nFixed direction of gravity helps the locomotion world a lot (Especially in a direction that always enforces meaningful contacts with the world). ****While the Visual Dexterity had to add some reward terms just to make the fingers “touch” the object, Rapid Locomotion did not have to do those — gravity were on their side.\nTC: it highly depends on the robot morphology and tasks themselves.\nYH: @Tao Chen Yeah, this gravity issue being task-dependent makes sense as well. Gravity direction in the vegetable peeling system, for instance, is helping the vegetable to at least stay at the palm.. But I guess the main point here was to point out that gravity can be applied in an adversarial manner for some dexterous manipulation scenarios 🙂\nLocomotion world usually defines the task reward to track the time-derivatives, rather than to explicitly reach a far-away spatial goal. This was a natural choice for locomotion tasks, since it’s intuitive to command a quadruped to walk or run forward, rather than telling it to reach a certain point in xy space. This can be a better choice in a sense that it’s more of a “short-horizon” task than actually reaching a certain goal. For dexterous manipulation paper, things are quite different. It’s quite common to train a policy that is set to “reach” a certain goal, which can be quite long-horizon task.\nWhile it’s not really easy to overcome the adversarial gravity issue for dexterous manipulation tasks, it’s rather easy to try the idea of tracking the time-derivatives instead of reaching certain spatial goal. In fact, some of the papers actually tried this in a limited sense (training policies to rotate around certain axis, rather than to reach certain goal).\nIn addition, replacing the auxiliary rewards (which are basically just soft constraints) with other constraint enforcing techniques are being explored in the locomotion domain as well. This can be a natural extension to deploy in the dexterous manipulation world, also using a lot of auxiliary rewards in its formulation.\nNot Only Rewards But Also Constraints: Applications on Legged…\nRL techniques: Curriculum Learning One major training technique that allowed Rapid Locomotion (Margolis et al.) achieve its impressive robustness and speed was curriculum learning — gradually increasing the complexity of the task over the course of training. The challenge there was to design the right curriculum, giving appropriately difficult tasks at the right stage of training, i.e., Box-Adaptive/Grid-Adaptive curriculum.\nExtending this idea to dexterous manipulation seems straightforward. Adapting the task reward of “velocity tracking” allows a natural extension of Rapid Locomotion’s curriculum learning technique. Applying curriculum learning for goal-reaching task reward might be a bit more sophisticated, but coming up with a nice curriculum learning strategy either way might be a nice addition to the dexterous manipulation world.\nTC: in manipulation, people also use curriculum learning. whether one uses it or not depends on the tasks again. sometimes they don’t provide significant benefits, while other times it can be very beneficial\nAlthough it wasn’t used in Rapid Locomotion paper, there are also line of works that runs curriculum learning over different terrains — using the “terrain generation” technique to control the ****difficulty of terrains accordingly over the course of training.\nAssessing Evolutionary Terrain Generation Methods for Curriculum…\nGuided Curriculum Learning for Walking Over Complex Terrain\nOne that’s analogous to controlling the complexity of terrain over the course of training might be giving increasingly complex objects during training — which is not really straightforward. How do we define the complexity for an object? While object properties like friction, mass are quite straightforward to implement a curriculum over, creating 3D shapes with increasing complexity is not really simple. But there’s still some possibility here too — there are some impressive works in training generative models for 3D shapes these days.\nFailure Recovery Since a quadruped can do pretty much nothing when it’s flipped over (or in some different failure state) there are line of works that focuses on “failure recovery” behaviors in locomotion domain, one example including the one below:\nRobust Recovery Motion Control for Quadrupedal Robots via Learned…\nThis failure recovery system is a nice addition to the system, giving more autonomy in general, better dealing with corner cases. Dexterous manipulation world can also adapt a similar system as well — for instance, regrasping the object and trying reorientation again when the object drops over the course of actions.\nP.S. This might be the only component that can be more easily implemented in dexterous manipulation world than locomotion world — grasping again and trying again might suffice as a nice failure recovery strategy.\nSim2Real - DR Again, comparing Visual Dexterity and Rapid Locomotion — Domain Randomization were very similarly applied. Besides some extra randomizations done on state observations and control parameters in Visual Dexterity paper, the core components of DR were quite identical.\nSim2Real - SysID System Identification (SysID) is a nice complement to Domain Randomization technique when it comes to Sim2Real issues. As clearly stated in the Visual Dexterity paper, extreme domain randomizations can lead the policy to be overly conservative, leading to sub-optimal performance. SysID can be a nice solution to this problem.\nOne of the SysID (+ online adaptation) techniques that locomotion domain often uses is a technique called RMA (Rapid Motor Adaptation). It abstracts various terrain properties in a form of latent vector during training, and tries to infer the terrain properties (in a form of latent) given the history of actions and observations.\nRMA: Rapid Motor Adaptation for Legged Robots\nThis technique adapts the usual form of teacher-student training leveraging previleged information, but adds a component where it explicitly conditions the policy with an implicit estimation of the system based on past interaction histories. It was proven to be effective in dealing with extremely diverse terrain scenarios.\nAdapting this online SysID technique to dexterous manipulation is very straight-foward — and the paper below (also from Malik’s group) exactly did that.\nIn-Hand Object Rotation via Rapid Motor Adaptation\nVisual Dexterity paper also did some important SysID, at robot dynamics level. Leveraging the massively parallel simulator, it estimated the right parameters for robot dynamics, removing one layer of Sim2Real.\nWhat other SysID techniques from locomotion domain can we use for dexterous manipulation?\n","wordCount":"1992","inLanguage":"en","datePublished":"2023-09-20T14:27:59-05:00","dateModified":"2023-09-20T14:27:59-05:00","author":{"@type":"Person","name":"Younghyo Park"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://younghyopark.me/blog/posts/locomotion-and-dexterous-manipulation/"},"publisher":{"@type":"Organization","name":"Younghyo's Blog","logo":{"@type":"ImageObject","url":"https://younghyopark.me/blog/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://younghyopark.me/blog accesskey=h title="Younghyo's Blog (Alt + H)"><img src=https://younghyopark.me/apple-touch-icon.png alt aria-label=logo height=35>Younghyo's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://younghyopark.me/blog/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://younghyopark.me/blog/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://younghyopark.me/ title="About Me"><span>About Me</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://younghyopark.me/blog>Home</a>&nbsp;»&nbsp;<a href=https://younghyopark.me/blog/posts/>Posts</a></div><h1 class=post-title>Multi-fingered Dexterous Manipulation from Locomotion Perspective</h1><div class=post-meta><span title='2023-09-20 14:27:59 -0500 -0500'>September 20, 2023</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;1992 words&nbsp;·&nbsp;Younghyo Park</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>&nbsp; &nbsp;Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#motivation>Motivation</a></li><li><a href=#differences-at-a-glance>Differences at a glance</a></li><li><a href=#terrain-generations-vs-object-datasets>Terrain Generations vs Object Datasets</a></li><li><a href=#rewards>Rewards</a></li><li><a href=#rl-techniques-curriculum-learning>RL techniques: Curriculum Learning</a></li><li><a href=#failure-recovery>Failure Recovery</a></li><li><a href=#sim2real---dr>Sim2Real - DR</a></li><li><a href=#sim2real---sysid>Sim2Real - SysID</a></li></ul></nav></div></details></div><div class=post-content><h2 id=motivation>Motivation<a hidden class=anchor aria-hidden=true href=#motivation>#</a></h2><p>Although it seems like a totally different class of work in robotics, Locomotion and Dexterous Manipulation in fact has some weird similarities — both work with a similar hardware (set of multiple identical kinematic chains) and the nature of the task itself (making selective contacts with an object to achieve the goal) is also very similar.</p><center><figure><img loading=lazy src=https://share.cleanshot.com/RqBf9n4z+ alt="Locmotion and Multi-fingered Dexterous Manipulation share many similarities." width=80%><figcaption><p>Locmotion and Multi-fingered Dexterous Manipulation share many similarities.</p></figcaption></figure></center><p>Of course there are huge differences in detail, but still, it’s similar enough to make one wonder</p><blockquote><p><strong>“What kind of lessons can we take from quadruped locomotion for dexterous manipulation, or, vice-versa?”</strong></p></blockquote><p>In fact, I’m already seeing some papers with a similar motivation — recent paper from Malik’s group that adapts the idea of RMA (a technique mainly used for locomotion) for dexterous manipulation <a href=https://proceedings.mlr.press/v205/qi23a.html>In-Hand Object Rotation via Rapid Motor Adaptation | pdf</a> is definitely one of them.</p><p>This post aims to discuss things that one can learn and adapt from one another — <strong>techniques from locomotion domain that can be applied to dexterous manipulation, and vice-versa.</strong></p><h2 id=differences-at-a-glance>Differences at a glance<a hidden class=anchor aria-hidden=true href=#differences-at-a-glance>#</a></h2><table><thead><tr><th></th><th><strong>Dexterous Manipulation</strong></th><th><strong>Locomotion</strong></th></tr></thead><tbody><tr><td>contact made with</td><td>diverse (graspable) objects</td><td>diverse terrains</td></tr><tr><td>diversity of “object/terrain” handled with</td><td>dataset of objects</td><td></td></tr><tr><td>(e.g. parts of ShapeNet)</td><td>procedural process of random terrain generation</td><td></td></tr><tr><td>contact location</td><td>all parts of hand — finger tips, fingers, palm</td><td>usually only with their round feet</td></tr><tr><td>gravity direction</td><td>entire SO(3), especially when attached to arm</td><td>generally downwards, slightly changes when climing uphill/downhill</td></tr><tr><td>degrees of freedom</td><td>16 dof (4 x 4 for each fingers)*</td><td>12 dof (4 x 3 for each leg)</td></tr><tr><td>typical state inputs to the policy</td><td>depth + proprioceptive (visual information is crucial)</td><td>proprioceptive (mostly don’t require visual information)</td></tr><tr><td>Rewards during RL</td><td>tracking explicit spatial goals (e.g. SE(3) poses) + some auxiliary rewards</td><td>tracking time-derivatives (e.g. body velocity) + some auxiliary rewards</td></tr><tr><td>Sim2Real - DR</td><td>randomizes object friction, size, mass, joint control parameters, …</td><td>randomizes terrain, ground friction, restitution, body mass/com ..</td></tr><tr><td>Sim2Real - SysID</td><td>e.g. robot dynamics sysID with massively parallel simulator</td><td>e.g. RMA (online sysID/adaptation during test-time)</td></tr><tr><td>RL techniques</td><td>student-teacher learning</td><td>student-teacher learning, curriculum learning (e.g. increasing difficulties of terrain, tracking velocity)</td></tr><tr><td>failure recovery</td><td>-</td><td>often trains separate policy that can recover from fallen down states</td></tr><tr><td>other trends</td><td>tactile sensors being added to make the policy more robust</td><td>better constraint handling techniques other than reward shaping <a href=https://arxiv.org/pdf/2308.12517.pdf>https://arxiv.org/pdf/2308.12517.pdf</a> are gaining attention these days</td></tr></tbody></table><p>Let’s further anaylze these differences in detail.</p><h2 id=terrain-generations-vs-object-datasets>Terrain Generations vs Object Datasets<a hidden class=anchor aria-hidden=true href=#terrain-generations-vs-object-datasets>#</a></h2><p>As far as I know, locomotion policies are trained over randomized terrains that’s generated by some heuristic algorithms (e.g. using Perlin noise two generate 2d heightmaps, diamond square algorithm for fractal terrains). Basically, they rely on <strong>“terrain generation algorithms”</strong> rather than a fixed dataset of terrains.</p><ul><li><p>summarization about terrain generation techniques from some paper ..</p><p><a href=https://arxiv.org/abs/2208.07681>Generating a Terrain-Robustness Benchmark for Legged Locomotion: A&mldr;</a></p><blockquote><p>Terrains, in the domain of terrain-aware legged locomotion, are typically represented by heightmaps, i.e., twodimensional matrices of real numbers indicating the height at different points. A traditional method for terrain generation is to use Perlin noise [19], as is adopted by existing works [3] [7]. Although policies can be trained in simulation with such terrains, verifications must be done on real robots after sim-to-real transfer, because using Perlin noise does not lead to realistic heightmaps [9].</p><p>Alternative methods are to generate fractal terrains, e.g., to use the diamond square algorithm [20] and the fractal brownian motion algorithm [21]. However, it is difficult to
regard them as realistic.</p><p>An emerging way to generate realistic terrains is to use GANs [22], where a discriminator tries to classify whether a sample comes from the dataset, and a generator tries to cheat the discriminator by generating samples from noises. Examples of GAN-based terrain generation are [23] and [24]. Yet, to achieve partially controllable generation and actively generate a dataset, we need interactive terrain authoring based on conditional GANs [10]. To be specific, the discriminator classifies whether the samples together with certain features are from the training dataset, and the generator generates fake samples from not only noises but also the features. Finally, the generator can generate realistic terrains from given input features, and the noises only affect smallscale details.</p></blockquote></li></ul><p>This approach relies to the hope that such synthesized terrains well reflects the diverse characteristics of real-world terrains (at least locally) so that the trained controller will well-behave in real-world. Major benefit of using terrain generation methods (with explicit parameters) is that we can control the difficulties of the task by adjusting parameter of terrain generation — which leads to the concept of curriculum learning as well.</p><p>On the other hand, dexterous manipulation relies on a fixed (but sufficiently large) training dataset of objects. This approach relies to the hope that the training dataset covers wide enough variety of objects so that the trained policy can be well generalized over unseen objects as well — which can sometimes be a bit unrealistic considering the vast range of objects. Also, it’s quite difficult to introduce a notion of “difficulty” in terms of object in this setting — which is also not really suited for curriculum learning setting as well.</p><p>It is thus natural, but still not straightforward, to think whether we can use the same approach of terrain generation in dexterous manipulation — using <strong>3D shape generation methods during training, instead of fixed object datasets.</strong></p><p>TC: it’s tempting to think about applying techniques used in locomotion to manipulation. but rather than think about the techniques themselves, might be better to start with what are we trying to achieve by transferring the techniques? why?</p><h2 id=rewards>Rewards<a hidden class=anchor aria-hidden=true href=#rewards>#</a></h2><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/2e5d1cce-f718-4358-b917-cc3d225eb659/f32c2b65-f20f-40b7-af68-43866219dbb7/Untitled.png alt=Untitled></p><p>As a great exemplary of both worlds, I took the formulations Visual Dexterity (Chen et al.) and Rapid Locomotion (Margolis et al.) to compare the rewardsterms . There were two observations:</p><ol><li><p><strong>Fixed direction of gravity helps the locomotion world a lot</strong> (Especially in a direction that always enforces meaningful contacts with the world). ****While the Visual Dexterity had to add some reward terms just to make the fingers “touch” the object, Rapid Locomotion did not have to do those — gravity were on their side.</p><p>TC: it highly depends on the robot morphology and tasks themselves.</p><p>YH: @Tao Chen Yeah, this gravity issue being task-dependent makes sense as well. Gravity direction in the vegetable peeling system, for instance, is helping the vegetable to at least stay at the palm.. But I guess the main point here was to point out that gravity <em>can</em> be applied in an adversarial manner for some dexterous manipulation scenarios 🙂</p></li><li><p>Locomotion world usually defines the task reward to <strong>track the time-derivatives</strong>, rather than to explicitly reach a far-away spatial goal. This was a natural choice for locomotion tasks, since it’s intuitive to command a quadruped to walk or run forward, rather than telling it to reach a certain point in xy space. This can be a better choice in a sense that it’s more of a “short-horizon” task than actually reaching a certain goal. For dexterous manipulation paper, things are quite different. It’s quite common to train a policy that is set to “reach” a certain goal, which can be quite long-horizon task.</p></li></ol><p>While it’s not really easy to overcome the adversarial gravity issue for dexterous manipulation tasks, <strong>it’s rather easy to try the idea of tracking the time-derivatives instead of reaching certain spatial goal.</strong> In fact, some of the papers actually tried this in a limited sense (training policies to rotate around certain axis, rather than to reach certain goal).</p><p>In addition, replacing the auxiliary rewards (which are basically just soft constraints) with other constraint enforcing techniques are being explored in the locomotion domain as well. This can be a natural extension to deploy in the dexterous manipulation world, also using a lot of auxiliary rewards in its formulation.</p><p><a href=https://arxiv.org/abs/2308.12517>Not Only Rewards But Also Constraints: Applications on Legged&mldr;</a></p><h2 id=rl-techniques-curriculum-learning>RL techniques: Curriculum Learning<a hidden class=anchor aria-hidden=true href=#rl-techniques-curriculum-learning>#</a></h2><p>One major training technique that allowed Rapid Locomotion (Margolis et al.) achieve its impressive robustness and speed was <strong>curriculum learning</strong> — gradually increasing the complexity of the task over the course of training. The challenge there was to design the right curriculum, giving appropriately difficult tasks at the right stage of training, i.e., Box-Adaptive/Grid-Adaptive curriculum.</p><p>Extending this idea to dexterous manipulation seems straightforward. Adapting the task reward of “velocity tracking” allows a natural extension of Rapid Locomotion’s curriculum learning technique. Applying curriculum learning for goal-reaching task reward might be a bit more sophisticated, but coming up with a nice curriculum learning strategy either way might be a nice addition to the dexterous manipulation world.</p><p>TC: in manipulation, people also use curriculum learning. whether one uses it or not depends on the tasks again. sometimes they don’t provide significant benefits, while other times it can be very beneficial</p><p>Although it wasn’t used in Rapid Locomotion paper, there are also line of works that runs curriculum learning over different terrains — using the “terrain generation” technique to control the ****difficulty of terrains accordingly over the course of training.</p><p><a href=https://arxiv.org/abs/2203.15172>Assessing Evolutionary Terrain Generation Methods for Curriculum&mldr;</a></p><p><a href=https://arxiv.org/abs/2010.03848>Guided Curriculum Learning for Walking Over Complex Terrain</a></p><p>One that’s analogous to controlling the complexity of terrain over the course of training might be giving increasingly complex objects during training — which is not really straightforward. How do we define the complexity for an object? While object properties like friction, mass are quite straightforward to implement a curriculum over, creating 3D shapes with increasing complexity is not really simple. But there’s still some possibility here too — there are some impressive works in training generative models for 3D shapes these days.</p><h2 id=failure-recovery>Failure Recovery<a hidden class=anchor aria-hidden=true href=#failure-recovery>#</a></h2><p>Since a quadruped can do pretty much nothing when it’s flipped over (or in some different failure state) there are line of works that focuses on “failure recovery” behaviors in locomotion domain, one example including the one below:</p><p><a href=https://arxiv.org/abs/2306.12712>Robust Recovery Motion Control for Quadrupedal Robots via Learned&mldr;</a></p><p>This failure recovery system is a nice addition to the system, giving more autonomy in general, better dealing with corner cases. Dexterous manipulation world can also adapt a similar system as well — for instance, regrasping the object and trying reorientation again when the object drops over the course of actions.</p><p>P.S. This might be the only component that can be more easily implemented in dexterous manipulation world than locomotion world — grasping again and trying again might suffice as a nice failure recovery strategy.</p><h2 id=sim2real---dr>Sim2Real - DR<a hidden class=anchor aria-hidden=true href=#sim2real---dr>#</a></h2><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/2e5d1cce-f718-4358-b917-cc3d225eb659/88accf86-e2fb-42c0-9493-2b321ce14c6f/Untitled.png alt=Untitled></p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/2e5d1cce-f718-4358-b917-cc3d225eb659/d724a277-6f64-4b16-997f-9afdb42504cc/Untitled.png alt=Untitled></p><p>Again, comparing Visual Dexterity and Rapid Locomotion — Domain Randomization were very similarly applied. Besides some extra randomizations done on state observations and control parameters in Visual Dexterity paper, the core components of DR were quite identical.</p><h2 id=sim2real---sysid>Sim2Real - SysID<a hidden class=anchor aria-hidden=true href=#sim2real---sysid>#</a></h2><p>System Identification (SysID) is a nice complement to Domain Randomization technique when it comes to Sim2Real issues. As clearly stated in the Visual Dexterity paper, extreme domain randomizations can lead the policy to be overly conservative, leading to sub-optimal performance. SysID can be a nice solution to this problem.</p><p>One of the SysID (+ online adaptation) techniques that locomotion domain often uses is a technique called RMA (Rapid Motor Adaptation). <strong>It abstracts various terrain properties in a form of latent vector during training,</strong> and tries to infer the terrain properties (in a form of latent) given the history of actions and observations.</p><p><a href=https://arxiv.org/abs/2107.04034>RMA: Rapid Motor Adaptation for Legged Robots</a></p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/2e5d1cce-f718-4358-b917-cc3d225eb659/575a0bf8-0839-4b8e-926d-bbd919bf9755/Untitled.png alt=Untitled></p><p>This technique adapts the usual form of teacher-student training leveraging previleged information, but adds a component where it explicitly conditions the policy with an implicit estimation of the system based on past interaction histories. It was proven to be effective in dealing with extremely diverse terrain scenarios.</p><p>Adapting this online SysID technique to dexterous manipulation is very straight-foward — and the paper below (also from Malik’s group) exactly did that.</p><p><a href=https://proceedings.mlr.press/v205/qi23a.html>In-Hand Object Rotation via Rapid Motor Adaptation</a></p><p>Visual Dexterity paper also did some important SysID, at robot dynamics level. Leveraging the massively parallel simulator, it estimated the right parameters for robot dynamics, removing one layer of Sim2Real.</p><p><strong>What other SysID techniques from locomotion domain can we use for dexterous manipulation?</strong></p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://younghyopark.me/blog/posts/automating-behavior-generation/><span class=title>« Prev</span><br><span>Automating Solvers for Behavior Generation</span></a>
<a class=next href=https://younghyopark.me/blog/posts/trip-to-maine/><span class=title>Next »</span><br><span>Trip to Maine</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Multi-fingered Dexterous Manipulation from Locomotion Perspective on twitter" href="https://twitter.com/intent/tweet/?text=Multi-fingered%20Dexterous%20Manipulation%20from%20Locomotion%20Perspective&amp;url=https%3a%2f%2fyounghyopark.me%2fblog%2fposts%2flocomotion-and-dexterous-manipulation%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Multi-fingered Dexterous Manipulation from Locomotion Perspective on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyounghyopark.me%2fblog%2fposts%2flocomotion-and-dexterous-manipulation%2f&amp;title=Multi-fingered%20Dexterous%20Manipulation%20from%20Locomotion%20Perspective&amp;summary=Multi-fingered%20Dexterous%20Manipulation%20from%20Locomotion%20Perspective&amp;source=https%3a%2f%2fyounghyopark.me%2fblog%2fposts%2flocomotion-and-dexterous-manipulation%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Multi-fingered Dexterous Manipulation from Locomotion Perspective on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fyounghyopark.me%2fblog%2fposts%2flocomotion-and-dexterous-manipulation%2f&title=Multi-fingered%20Dexterous%20Manipulation%20from%20Locomotion%20Perspective"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Multi-fingered Dexterous Manipulation from Locomotion Perspective on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyounghyopark.me%2fblog%2fposts%2flocomotion-and-dexterous-manipulation%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Multi-fingered Dexterous Manipulation from Locomotion Perspective on whatsapp" href="https://api.whatsapp.com/send?text=Multi-fingered%20Dexterous%20Manipulation%20from%20Locomotion%20Perspective%20-%20https%3a%2f%2fyounghyopark.me%2fblog%2fposts%2flocomotion-and-dexterous-manipulation%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Multi-fingered Dexterous Manipulation from Locomotion Perspective on telegram" href="https://telegram.me/share/url?text=Multi-fingered%20Dexterous%20Manipulation%20from%20Locomotion%20Perspective&amp;url=https%3a%2f%2fyounghyopark.me%2fblog%2fposts%2flocomotion-and-dexterous-manipulation%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://younghyopark.me/blog>Younghyo's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>